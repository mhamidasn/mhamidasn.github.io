---
title: "Enhancing 3D Lung Infection Segmentation with 2D U-Shaped Deep Learning Variants"
collection: publications
permalink: /publication/pub_8
date: 2023-10-24
excerpt: '**Abstract**<br>Accurate lung segmentation plays a vital role in generating 3D projections of lung infections, which contribute to the diagnosis and treatment planning of various lung diseases, including cases like COVID-19. This study capitalizes on the capabilities of deep learning techniques to reconstruct 3D lung projections from CT-scans. In this pursuit, we employ well-established 2D architectural frameworks like UNet, LinkNet, Attention UNet, UNet 3+, and TransUNet. The dataset used comprises 20 3D CT-scans from COVID-19 patients, resulting in over 2900 raw 2D slices. Following preprocessing, the dataset is refined to encompass 2560 2D slices tailored for modeling. Preprocessing procedures involve mask refinement, image resizing, contrast limited adaptive histogram equalization (CLAHE), and image augmentation to enhance the data quality and diversity. Evaluation metrics, including Intersection over Union (IoU) and dice scores, are used to assess the models’ performance. Among the models tested, Attention UNet stands out, demonstrating the highest performance. Its key trait of harnessing attention mechanisms enhances its ability to focus on crucial features. This translates to exceptional results, with an IoU score of 85.36% and dice score of 91.49%. These findings provide valuable insights into guiding the selection of an appropriate architecture tailored to specific requirements, considering factors such as segmentation accuracy and computational resources, in the context of 3D lung projection reconstruction.'
venue: 'MDPI Applied Sciences'
tags:
  - article paper
  - english
---
## Abstract
Accurate lung segmentation plays a vital role in generating 3D projections of lung infections, which contribute to the diagnosis and treatment planning of various lung diseases, including cases like COVID-19. This study capitalizes on the capabilities of deep learning techniques to reconstruct 3D lung projections from CT-scans. In this pursuit, we employ well-established 2D architectural frameworks like UNet, LinkNet, Attention UNet, UNet 3+, and TransUNet. The dataset used comprises 20 3D CT-scans from COVID-19 patients, resulting in over 2900 raw 2D slices. Following preprocessing, the dataset is refined to encompass 2560 2D slices tailored for modeling. Preprocessing procedures involve mask refinement, image resizing, contrast limited adaptive histogram equalization (CLAHE), and image augmentation to enhance the data quality and diversity. Evaluation metrics, including Intersection over Union (IoU) and dice scores, are used to assess the models’ performance. Among the models tested, Attention UNet stands out, demonstrating the highest performance. Its key trait of harnessing attention mechanisms enhances its ability to focus on crucial features. This translates to exceptional results, with an IoU score of 85.36% and dice score of 91.49%. These findings provide valuable insights into guiding the selection of an appropriate architecture tailored to specific requirements, considering factors such as segmentation accuracy and computational resources, in the context of 3D lung projection reconstruction.
<br>

## Other Information
<table>
  <tr>
    <td>Type</td>
    <td>:</td>
    <td>Article Paper</td>
  </tr>
  <tr>
    <td>Published in</td>
    <td>:</td>
    <td>MDPI Applied Sciences</td>
  </tr>
  <tr>
    <td>Special Issue</td>
    <td>:</td>
    <td>Convolutional Neural Network and Its Applications in Image Detection and Recognition</td>
  </tr>  
  <tr>
    <td>Written in</td>
    <td>:</td>
    <td>English</td>
  </tr>
</table>

[[Publication page]](https://www.mdpi.com/2076-3417/13/21/11640)
[[Download paper here]](https://www.mdpi.com/2076-3417/13/21/11640/pdf?version=1698164648)



**For proper citation, refer [here](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Enhancing+3D+Lung+Infection+Segmentation+with+2D+U-Shaped+Deep+Learning+Variants&btnG=#d=gs_cit&t=1698648079512&u=%2Fscholar%3Fq%3Dinfo%3ALs3dYubJRbIJ%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Did)**